Here’s a **single, heavily detailed Copilot prompt** you can paste into GitHub Copilot Chat (or Cursor/VSCode) to generate the **entire `concurrent-exchange-sim` C++20 project** end-to-end with the exact low-latency + mutex + semaphore focus you described.

> Tip: Paste this as one message, then follow it by:
> “Start by generating the repo structure + CMake + core headers, then implement modules in order.”

---

## Copilot Mega-Prompt (paste this)

You are an expert low-latency C++ engineer building a quant-grade multithreaded exchange simulator repo named **concurrent-exchange-sim**. Implement the full project in modern **C++20** with **high-throughput producer-consumer order ingestion**, a **matching engine**, a **cache-aware limit order book**, and **proof via tests + benchmarks**.

### 0) Non-negotiable requirements (must satisfy)

**Concurrency primitives**

* Use **`std::mutex`** for *data protection* of shared state (order book + accounts).
* Use **`std::counting_semaphore`** for *signaling & coordination* in a **bounded ring buffer** (no busy-wait loops).

**Low-latency engineering**

* No `std::map` / `std::list` for the LOB core structure.
* No dynamic allocation in the hot path after initialization. Use:

  * a preallocated **object pool** for `Order` storage, or a custom arena/ freelist allocator.
  * preallocated buffers (`std::vector::reserve`, fixed arrays, ring buffer fixed capacity).
* Emphasize **cache locality**, minimal pointer chasing, and predictable branching.
* Implement fast order-id lookup via:

  * `std::unordered_map` with reserved capacity + stable allocator, OR
  * a “dense hash map style” implementation (simple robin hood hashing) if feasible.
  * If time-constrained, do `unordered_map` with `reserve()` + `max_load_factor()` and document path to robin_hood.

**Project professionalism**

* Build system: **CMake**.
* Unit tests: **GoogleTest** (via FetchContent).
* Benchmarks: **Google Benchmark** (via FetchContent).
* Logging: “zero-allocation-ish” logger that never blocks matching thread: log events to a lock-free-ish queue (bounded ring) and have a background thread flush to file.
* Provide README with architecture diagrams (ASCII ok), build steps, and performance section including **P99 latency**.

**Modern C++20 usage**

* Use `std::jthread` for threads (auto join).
* Use `std::atomic_ref` for updating high-frequency stats (trade count, volume).
* Use `constexpr` / `consteval` where reasonable for enums and parsing tables.
* Use **Concepts** for template constraints (Numeric/Price/Qty types).
* Use `[[likely]]` / `[[unlikely]]` for hot-path branches.

**Platform**

* Target Linux first, but compile on Windows too.
* Thread affinity: Implement `pin_thread_to_core()` using `pthread_setaffinity_np` on Linux and a stub/no-op fallback for other platforms with clear docs.

---

### 1) Deliverables to generate in this repo

Create the full directory structure:

```
concurrent-exchange-sim/
  CMakeLists.txt
  cmake/
  include/
    ces/
      common/
        types.hpp
        time.hpp
        concepts.hpp
        macros.hpp
      concurrency/
        ring_buffer.hpp
        spsc_semaphore_queue.hpp
        pinning.hpp
      memory/
        object_pool.hpp
        arena.hpp
      lob/
        order.hpp
        price_level.hpp
        order_book.hpp
      engine/
        matching_engine.hpp
        trader.hpp
        accounts.hpp
        risk.hpp
      logging/
        async_logger.hpp
      metrics/
        latency.hpp
        stats.hpp
  src/
    main.cpp
    engine/matching_engine.cpp
    engine/trader.cpp
    engine/accounts.cpp
    lob/order_book.cpp
    logging/async_logger.cpp
    metrics/latency.cpp
  tests/
    CMakeLists.txt
    test_matching.cpp
    test_order_book.cpp
    test_ring_buffer.cpp
  benchmarks/
    CMakeLists.txt
    bench_order_book.cpp
    bench_engine_latency.cpp
  tools/
    replay_from_csv.cpp
  data/
    sample_orders.csv
  scripts/
    run_bench.sh
  README.md
  LICENSE
```

Use namespace `ces` (Concurrent Exchange Sim). Keep headers clean, minimal dependencies, and document invariants.

---

### 2) Architecture to implement

#### 2.1 Core flow

* Multiple **Trader** threads generate orders (or read from a replay file).
* Traders push `OrderEvent` into a **bounded ring buffer**:

  * `free_slots` semaphore tracks available slots
  * `filled_slots` semaphore tracks number of enqueued items
  * Producers do: `free_slots.acquire()` -> write -> `filled_slots.release()`
  * Consumer does: `filled_slots.acquire()` -> read -> `free_slots.release()`
* One **MatchingEngine** consumer thread reads events and applies them to the LOB.

#### 2.2 Order types

Support:

* `NewLimit` (buy/sell, price, qty, order_id, trader_id)
* `Cancel` (order_id)
* `Modify` (order_id, new_qty, optionally new_price treated as cancel+new)
* Optional: `NewMarket` (match immediately across levels)

Define strict validation rules and fast failure paths.

#### 2.3 Limit Order Book structure (cache-aware)

* Maintain two sides: bids and asks.
* No `std::map`.
* Use “flat levels”: `std::vector<PriceLevel>` sorted by price:

  * Bids: descending
  * Asks: ascending
* Each `PriceLevel` stores:

  * `price`
  * total qty
  * FIFO queue of orders at that price using indices into an **OrderPool** (intrusive linked list using integer indices, not pointers).
* `Order` stored in pool:

  * `order_id`, `trader_id`, `side`, `price`, `qty_remaining`
  * `next_idx`, `prev_idx` (intrusive list in pool)
* Maintain `order_id -> pool_index` lookup map for O(1) cancel/modify.

**Important:** initialization pre-reserves:

* max orders
* max price levels (or dynamic levels but vector reserved big)
* map reserved big with low load factor

#### 2.4 Thread safety policy (must be explicit)

* The matching engine is the *only writer* to the order book in the default mode.
* Still implement a **`std::mutex`** inside `OrderBook` guarding mutations, because:

  * You will optionally allow a read-only market data thread to snapshot book state concurrently (or allow multi-consumer future extension).
* Accounts:

  * `Accounts` is shared and protected by `std::mutex` per account or a striped mutex scheme.
  * Demonstrate the “ATM problem” is solved.

#### 2.5 Metrics (latency + tail)

* Add high-resolution timestamps on enqueue + after match.
* Maintain latency samples in a preallocated vector/ring.
* At end of run, compute:

  * mean, median, p95, **p99**, max
* Print summary.

---

### 3) Modules to implement (with acceptance criteria)

Implement in this order:

#### (A) Common types + concepts

* `Price` and `Qty` strong typedefs (or using aliases) with Concepts:

  * `Numeric` concept for arithmetic
  * ensure no accidental mixing (optional strong type wrapper)
* `Side` enum, `OrderType` enum, compile-time string->enum helper (`constexpr` lookup).

#### (B) Memory pool

* `ObjectPool<Order>`:

  * fixed capacity
  * O(1) allocate/free using freelist indices
  * no heap allocation after ctor
* Add debug checks in non-release builds.

#### (C) Semaphore-based bounded ring buffer

* `SpscSemaphoreQueue<OrderEvent, Capacity>`:

  * fixed capacity array
  * head/tail indices
  * `std::counting_semaphore<Capacity>` for free slots
  * `std::counting_semaphore<Capacity>` for filled slots
  * cacheline padding on head/tail to avoid false sharing
  * no mutex inside this queue
    Acceptance:
* Unit test that producer/consumer correctness holds under concurrency.

#### (D) Order book

* `OrderBook::add_limit()`, `cancel()`, `modify()`, `match()`
* Correct price-time priority matching.
* Return `Trade` events on match (filled qty, price, maker/taker ids).
* Implement best bid/ask retrieval.
* Keep levels vector sorted; insertion should be efficient:

  * use binary search then insert (levels reserved big)
  * future note: could use gap-buffer; for now implement with reserved vector + minimal moves and document it.
    Acceptance:
* Unit tests for partial fills, full fills, multiple levels, cancel, modify, empty book.

#### (E) Matching engine

* Owns `OrderBook`, `Accounts`, `AsyncLogger`, `Stats`.
* Consumer loop:

  * block on filled_slots semaphore
  * pop event
  * apply to book
  * update stats via `std::atomic_ref`
* Provide clean shutdown via stop token (`std::jthread` + `stop_source`).

#### (F) Traders (producers)

* Trader threads generate synthetic orders:

  * configurable rate, burstiness, random seed
  * use preallocated rng
* Optional CSV replay tool in `tools/`.

#### (G) Async logger

* Bounded lock-free-ish ring buffer for log messages (fixed size char buffers).
* Logger API:

  * `log(fmt_string, ...)` but avoid dynamic allocation:

    * use `std::snprintf` into fixed buffer entries
* Background thread flushes to file periodically.
  Acceptance:
* Engine thread never performs file I/O.

#### (H) Benchmarks

Use Google Benchmark:

* `BM_AddOrder`, `BM_CancelOrder`, `BM_MatchHotPath`
* `BM_EndToEndTickToTrade` measuring enqueue->match latency distribution (store samples, report p99).
  Acceptance:
* Bench runs via `ctest` optional; `./benchmarks/...` works.

#### (I) Tests

GoogleTest:

* deterministically test matching results
* concurrency test for queue (no data races)
* ensure cancel removes and doesn’t match later

---

### 4) Main program CLI

Create `src/main.cpp` implementing:

* CLI flags:

  * `--orders N`
  * `--traders T`
  * `--capacity C`
  * `--seed S`
  * `--pin` (enable pinning)
  * `--log file`
* At end print stats and latency percentiles.

---

### 5) Coding standards / performance settings

* Use `-O3 -DNDEBUG` in Release.
* Add `-march=native` optionally via CMake option `CES_NATIVE_OPT`.
* Put hot functions in headers only if beneficial; otherwise keep compiled sources.
* Use `[[likely]]` and `[[unlikely]]` on:

  * “book match occurs” likely
  * invalid order rejected unlikely
* Use `alignas(64)` or padding structs to avoid false sharing.

---

### 6) README content requirements

Generate a high-quality README with:

* What the project is (quant-style)
* Architecture diagram (ASCII)
* Build instructions (CMake)
* How to run simulation
* How to run tests and benchmarks
* Concurrency explanation: **mutex vs semaphore**
* Performance section with example output including **p99**
* Future work: robin hood map, gap buffer, lock-free snapshots, disruptor pipeline, market data websocket integration.

---

### 7) Implementation notes / guardrails

* Do not invent fake results; if you show sample benchmark output, mark it clearly as “example”.
* Ensure code compiles with C++20 on clang and gcc.
* Avoid overly complex templates; keep it readable but professional.
* Keep everything deterministic with seeds for tests.

---

### 8) Execute now

Start by generating:

1. top-level `CMakeLists.txt` with options (tests/benchmarks on/off), FetchContent for gtest/benchmark
2. the full header skeletons with TODOs removed
3. implement modules in the order listed (A→I)
4. ensure tests pass, then add benchmarks
5. finalize README

Return code for every created file with correct paths.

---

If you want, tell Copilot **“do it in commits”** and use these commit boundaries:

1. build + skeleton
2. pool + queue
3. order book
4. engine + traders
5. logger + metrics
6. tests
7. benchmarks
8. README polish
